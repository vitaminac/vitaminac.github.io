<!doctype html>
<html lang="en">
  <!-- Head tag -->
  <!-- SEO -->

  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>Java Concurrent Programming｜Gao&#39;s Blog</title>
    <meta
      property="og:title"
      content="Java Concurrent Programming｜Gao&#39;s Blog"
    />

    <meta
      name="description"
      content="Java Concurrent Programming｜Gao&#39;s Blog"
    />
    <meta
      property="og:description"
      content="Java Concurrent Programming｜Gao&#39;s Blog"
    />
    <meta name="author" content="Gao" />
    <meta name="robots" content="index, follow" />
    <meta
      property="og:image"
      content="https://vitaminac.github.io/images/favicon.jpg"
    />
    <link rel="shortcut icon" href="/images/favicon.jpg" />

    <meta
      name="keywords"
      content="Java,Concurrent Programming,Parallelism,Java Stream"
    />

    <meta name="theme-color" content="#600090" />
    <meta name="msapplication-navbutton-color" content="#600090" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="#600090" />
    <link
      rel="alternate"
      type="application/atom+xml"
      title="Gao&#39;s Blog"
      href="/atom.xml"
    />

    <link
      rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css"
      cross-origin="anonymous"
      referrer-policy="no-referrer"
    />
    <link
      rel="canonical"
      href="https://vitaminac.github.io/Java-Concurrent-Programming/"
    />

    <!-- jQuery -->
    <script
      type="text/javascript"
      src="https://code.jquery.com/jquery-3.6.0.min.js"
    ></script>
    <!-- Bootstrap -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css"
      integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC"
      crossorigin="anonymous"
    />
    <script
      src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js"
      integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.min.js"
      integrity="sha384-cVKIPhGWiC2Al4u+LWgxfKTRIcfu0JTxR+EQDz/bgldoEyl4H0zUF0QKbrJ0EcQF"
      crossorigin="anonymous"
    ></script>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/blog-style.css" />
    <link rel="stylesheet" href="/css/syntax.css" />

    <!-- Google Tag Manager -->

    <script>
      (function (w, d, s, l, i) {
        w[l] = w[l] || [];
        w[l].push({ "gtm.start": new Date().getTime(), event: "gtm.js" });
        var f = d.getElementsByTagName(s)[0],
          j = d.createElement(s),
          dl = l != "dataLayer" ? "&l=" + l : "";
        j.async = true;
        j.src = "https://www.googletagmanager.com/gtm.js?id=" + i + dl;
        f.parentNode.insertBefore(j, f);
      })(window, document, "script", "dataLayer", "GTM-WDC9JKC");
    </script>

    <!-- End Google Tag Manager -->

    <!-- Global site tag (gtag.js) - Google Analytics -->

    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=UA-151409235-1"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "UA-151409235-1");
    </script>

    <!-- Google AdSense -->
    <script
      data-ad-client="ca-pub-8356359077918854"
      async
      src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"
    ></script>
    <meta name="generator" content="Hexo 6.3.0" />
  </head>
  <style>
    header.intro-header {
      background-image: url("/images/header.gif");
    }
  </style>
  <!-- hack iOS CSS :active style -->

  <body ontouchstart="" class="animated fadeIn">
    <!-- Main Content -->

    <!--only post-->

    <img class="wechat-title-img" src="/" />

    <!-- Post Content -->
    <article>
      <div class="container">
        <div class="row">
          <!-- Post Container -->
          <div class="order-lg-2 col-lg-3 col-12 toc-col" style="z-index: 1">
            <ol class="toc">
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Introduction"
                  ><span class="toc-text">Introduction</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Reason"
                      ><span class="toc-text">Reason</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Process"
                      ><span class="toc-text">Process</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Sequential-Model"
                      ><span class="toc-text">Sequential Model</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Concurrent-Process"
                      ><span class="toc-text">Concurrent Process</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Multiprocess"
                      ><span class="toc-text">Multiprocess</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Multiprogramming"
                      ><span class="toc-text">Multiprogramming</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Race-Condition"
                      ><span class="toc-text">Race Condition</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Atomic-Operation"
                      ><span class="toc-text">Atomic Operation</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Fine-Grained"
                          ><span class="toc-text">Fine-Grained</span></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Coarse-Grained"
                          ><span class="toc-text">Coarse-Grained</span></a
                        >
                      </li>
                    </ol>
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Critical-Section"
                      ><span class="toc-text">Critical Section</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Preprotocol-x2F-Postprotocol"
                          ><span class="toc-text"
                            >Preprotocol&#x2F;Postprotocol</span
                          ></a
                        >
                      </li>
                    </ol>
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Mutual-Exclusion"
                      ><span class="toc-text">Mutual Exclusion</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Abstractions"
                  ><span class="toc-text">Abstractions</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Thread"
                  ><span class="toc-text">Thread</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Daemon"
                      ><span class="toc-text">Daemon</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Priority"
                      ><span class="toc-text">Priority</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Group"
                      ><span class="toc-text">Group</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Properties"
                      ><span class="toc-text">Properties</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Conditional-Synchronization"
                  ><span class="toc-text">Conditional Synchronization</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Barrier-Synchronization"
                      ><span class="toc-text">Barrier Synchronization</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Properties-of-Corrections"
                  ><span class="toc-text">Properties of Corrections</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Safety"
                      ><span class="toc-text">Safety</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Liveness"
                      ><span class="toc-text">Liveness</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Absence-of-Unnecessary-Delays"
                      ><span class="toc-text"
                        >Absence of Unnecessary Delays</span
                      ></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Fairness"
                      ><span class="toc-text">Fairness</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Parallelism"
                  ><span class="toc-text">Parallelism</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Computation-Graph-CGs"
                      ><span class="toc-text">Computation Graph (CGs)</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Work-and-Span"
                          ><span class="toc-text">Work and Span</span></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a
                          class="toc-link"
                          href="#Time-of-execution-and-Speedup"
                          ><span class="toc-text"
                            >Time of execution and Speedup</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Amdahl%E2%80%99s-Law"
                          ><span class="toc-text">Amdahl’s Law</span></a
                        >
                      </li>
                    </ol>
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Forkjoin"
                      ><span class="toc-text">Forkjoin</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Fork"
                          ><span class="toc-text">Fork</span></a
                        >
                      </li>
                    </ol>
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Join"
                      ><span class="toc-text">Join</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ForkJoinPool"
                      ><span class="toc-text">ForkJoinPool</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#MapReduce"
                      ><span class="toc-text">MapReduce</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Map"
                          ><span class="toc-text">Map</span></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Reduce"
                          ><span class="toc-text">Reduce</span></a
                        >
                      </li>
                    </ol>
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Future"
                  ><span class="toc-text">Future</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Get-Result"
                      ><span class="toc-text">Get Result</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Functional-Parallelism"
                      ><span class="toc-text">Functional Parallelism</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Memorization"
                  ><span class="toc-text">Memorization</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Determinism"
                  ><span class="toc-text">Determinism</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Functional-Determinism"
                      ><span class="toc-text">Functional Determinism</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Structural-Determinism"
                      ><span class="toc-text">Structural Determinism</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Data-Race"
                      ><span class="toc-text">Data Race</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Nondeterministic"
                      ><span class="toc-text">Nondeterministic</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Parallelism-Loop"
                  ><span class="toc-text">Parallelism Loop</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Barriers-in-Parallel-Loops"
                      ><span class="toc-text"
                        >Barriers in Parallel Loops</span
                      ></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Iteration-Grouping"
                      ><span class="toc-text">Iteration Grouping</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Phaser"
                  ><span class="toc-text">Phaser</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a
                      class="toc-link"
                      href="#Point-to-Point-Synchronization-with-Phasers-and-Dataflow-Synchronization"
                      ><span class="toc-text"
                        >Point-to-Point Synchronization with Phasers and
                        Dataflow Synchronization</span
                      ></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Pipeline-Parallelism"
                      ><span class="toc-text">Pipeline Parallelism</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Producer-x2F-Consumer"
                  ><span class="toc-text">Producer&#x2F;Consumer</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Reader-x2F-Writer"
                  ><span class="toc-text">Reader&#x2F;Writer</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Dining-Philosopher-Problem"
                  ><span class="toc-text">Dining Philosopher Problem</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Deadlock"
                      ><span class="toc-text">Deadlock</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Livelock"
                      ><span class="toc-text">Livelock</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Solution"
                      ><span class="toc-text">Solution</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Volatile"
                  ><span class="toc-text">Volatile</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Busy-Waiting"
                  ><span class="toc-text">Busy Waiting</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Dekker%E2%80%99s-algorithm"
                      ><span class="toc-text">Dekker’s algorithm</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a
                          class="toc-link"
                          href="#Mandatory-Alternation-Unnecessary-Delays"
                          ><span class="toc-text"
                            >Mandatory Alternation - Unnecessary Delays</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#No-Mutual-Exclusion"
                          ><span class="toc-text">No Mutual Exclusion</span></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Deadlock-1"
                          ><span class="toc-text">Deadlock</span></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a
                          class="toc-link"
                          href="#Starvation-Livelock-No-Mutual-Exclusion"
                          ><span class="toc-text"
                            >Starvation - Livelock - No Mutual Exclusion</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Final-Solution"
                          ><span class="toc-text">Final Solution</span></a
                        >
                      </li>
                    </ol>
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Semaphore"
                  ><span class="toc-text">Semaphore</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Development-Process"
                      ><span class="toc-text">Development Process</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a
                      class="toc-link"
                      href="#Conditional-Synchronization-With-Semaphore"
                      ><span class="toc-text"
                        >Conditional Synchronization With Semaphore</span
                      ></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Mutual-Exclusion-with-Semaphore"
                      ><span class="toc-text"
                        >Mutual Exclusion with Semaphore</span
                      ></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a
                      class="toc-link"
                      href="#Barrier-with-Semaphore-First-Example"
                      ><span class="toc-text"
                        >Barrier with Semaphore First Example</span
                      ></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#First-Incorrect-Approach"
                          ><span class="toc-text"
                            >First Incorrect Approach</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Second-Incorrect-Approach"
                          ><span class="toc-text"
                            >Second Incorrect Approach</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#First-Correct-Approach"
                          ><span class="toc-text"
                            >First Correct Approach</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Second-Correct-Approach"
                          ><span class="toc-text"
                            >Second Correct Approach</span
                          ></a
                        >
                      </li>
                    </ol>
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Barrier-with-Semaphore"
                      ><span class="toc-text">Barrier with Semaphore</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#K-Mutual-Exclusion"
                      ><span class="toc-text">K Mutual Exclusion</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Buffer"
                      ><span class="toc-text">Buffer</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Reader-x2F-Writer-With-Semaphore"
                      ><span class="toc-text"
                        >Reader&#x2F;Writer With Semaphore</span
                      ></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Lock"
                  ><span class="toc-text">Lock</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Structured-locks"
                      ><span class="toc-text">Structured locks</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Synchronized-Block"
                          ><span class="toc-text">Synchronized Block</span></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Synchronized-Method"
                          ><span class="toc-text">Synchronized Method</span></a
                        >
                      </li>
                    </ol>
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Lock-Interface"
                      ><span class="toc-text">Lock Interface</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ReentrantLock"
                      ><span class="toc-text">ReentrantLock</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ReadWriteLock"
                      ><span class="toc-text">ReadWriteLock</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#StampedLock"
                      ><span class="toc-text">StampedLock</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Monitor"
                  ><span class="toc-text">Monitor</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Exchanger"
                  ><span class="toc-text">Exchanger</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#CountDownLatch"
                  ><span class="toc-text">CountDownLatch</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#CyclicBarrier"
                  ><span class="toc-text">CyclicBarrier</span></a
                >
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Concurrent-Collections"
                  ><span class="toc-text">Concurrent Collections</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Synchronization-Wrappers"
                      ><span class="toc-text">Synchronization Wrappers</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#BlockingQueue"
                      ><span class="toc-text">BlockingQueue</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ConcurrentMap"
                      ><span class="toc-text">ConcurrentMap</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#CopyOnWrite"
                      ><span class="toc-text">CopyOnWrite</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#CopyOnWriteArrayList"
                          ><span class="toc-text">CopyOnWriteArrayList</span></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#CopyOnWriteArraySet"
                          ><span class="toc-text">CopyOnWriteArraySet</span></a
                        >
                      </li>
                    </ol>
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ConcurrentSkipListSet"
                      ><span class="toc-text">ConcurrentSkipListSet</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ConcurrentLinkedQueue"
                      ><span class="toc-text">ConcurrentLinkedQueue</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ConcurrentLinkedDeque"
                      ><span class="toc-text">ConcurrentLinkedDeque</span></a
                    >
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Thread-Pool"
                  ><span class="toc-text">Thread Pool</span></a
                >
                <ol class="toc-child">
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#Executor"
                      ><span class="toc-text">Executor</span></a
                    >
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ExecutorService"
                      ><span class="toc-text">ExecutorService</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a class="toc-link" href="#Shutdown"
                          ><span class="toc-text">Shutdown</span></a
                        >
                      </li>
                    </ol>
                  </li>
                  <li class="toc-item toc-level-3">
                    <a class="toc-link" href="#ScheduledExecutorService"
                      ><span class="toc-text">ScheduledExecutorService</span></a
                    >
                    <ol class="toc-child">
                      <li class="toc-item toc-level-4">
                        <a
                          class="toc-link"
                          href="#schedule-Callable-task-long-delay-TimeUnit-timeunit"
                          ><span class="toc-text"
                            >schedule(Callable task, long delay, TimeUnit
                            timeunit)</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a
                          class="toc-link"
                          href="#schedule-Runnable-task-long-delay-TimeUnit-timeunit"
                          ><span class="toc-text"
                            >schedule(Runnable task, long delay, TimeUnit
                            timeunit)</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a
                          class="toc-link"
                          href="#scheduleAtFixedRate-Runnable-task-long-initialDelay-long-period-TimeUnit-timeunit"
                          ><span class="toc-text"
                            >scheduleAtFixedRate(Runnable task, long
                            initialDelay, long period, TimeUnit timeunit)</span
                          ></a
                        >
                      </li>
                      <li class="toc-item toc-level-4">
                        <a
                          class="toc-link"
                          href="#scheduleWithFixedDelay-Runnable-task-long-initialDelay-long-period-TimeUnit-timeunit"
                          ><span class="toc-text"
                            >scheduleWithFixedDelay(Runnable task, long
                            initialDelay, long period, TimeUnit timeunit)</span
                          ></a
                        >
                      </li>
                    </ol>
                  </li>
                </ol>
              </li>
              <li class="toc-item toc-level-2">
                <a class="toc-link" href="#Reference"
                  ><span class="toc-text">Reference</span></a
                >
              </li>
            </ol>
          </div>

          <div class="order-lg-1 col-lg-9 col-12 post-container">
            <h2 id="Introduction">
              <a
                href="#Introduction"
                class="headerlink"
                title="Introduction"
              ></a
              >Introduction
            </h2>
            <p>
              At the beginning, a program ran from <strong>start</strong> to
              <strong>finish</strong>, it had access to
              <strong>all resources</strong> on the system. Nowadays with
              <strong>operating systems</strong> we are allowed to run various
              programs simultaneously in processes
              <strong>independent of the hardware architecture</strong> we have.
            </p>
            <h3 id="Reason">
              <a href="#Reason" class="headerlink" title="Reason"></a>Reason
            </h3>
            <ol>
              <li>
                Take advantage of the
                <strong>IO operations waiting time</strong> to do other tasks.
              </li>
              <li>
                A better strategy, sharing resources instead of waiting them.
              </li>
              <li>Divide into various <strong>independent tasks</strong>.</li>
            </ol>
            <h3 id="Process">
              <a href="#Process" class="headerlink" title="Process"></a>Process
            </h3>
            <p>
              The execution of a computer program. Each
              <strong>process</strong> had its own memory space for instructions
              and data. The same computer program can run multiple times, with
              some <strong>overlap</strong> and <strong>simultaneously</strong>.
            </p>
            <h3 id="Sequential-Model">
              <a
                href="#Sequential-Model"
                class="headerlink"
                title="Sequential Model"
              ></a
              >Sequential Model
            </h3>
            <p>
              They executed the instructions <strong>sequentially</strong>,
              interacting with the outside to through I&#x2F;O where it is
              <strong>perfectly defined</strong> what instruction will run next.
            </p>
            <p>
              <img src="sequential-processing.png" alt="Sequential Model" />
            </p>
            <h3 id="Concurrent-Process">
              <a
                href="#Concurrent-Process"
                class="headerlink"
                title="Concurrent Process"
              ></a
              >Concurrent Process
            </h3>
            <p>
              P1 and P2 are said to be two processes
              <strong>concurrent</strong> if the first instruction of one of
              them run between the first and the last instruction of the other.
              They can be independent, competing the resources or cooperative.
              The interations between concurrent processes are carried out
              through the <strong>synchronization</strong> and
              <strong>communication</strong>. The order of instructions is not
              guaranteed. The results of executions may vary.
            </p>
            <p><img src="concurrent-process.png" alt="Concurrent Process" /></p>
            <h3 id="Multiprocess">
              <a
                href="#Multiprocess"
                class="headerlink"
                title="Multiprocess"
              ></a
              >Multiprocess
            </h3>
            <p>They run in different processors at the same time.</p>
            <p><img src="multiprocess.png" alt="Multiprocess" /></p>
            <h3 id="Multiprogramming">
              <a
                href="#Multiprogramming"
                class="headerlink"
                title="Multiprogramming"
              ></a
              >Multiprogramming
            </h3>
            <p>
              They are assigned to the same processor and execute in different
              time slots. You can take advantage of the processor while a
              process waits for input&#x2F;output.
            </p>
            <p><img src="multiprogramming.png" alt="Multiprogramming" /></p>
            <h3 id="Race-Condition">
              <a
                href="#Race-Condition"
                class="headerlink"
                title="Race Condition"
              ></a
              >Race Condition
            </h3>
            <p>
              In the concurrent context, multiple control flows can access,
              modify the same resource at the same time and produces
              <strong>unexpected result</strong>.
            </p>
            <h3 id="Atomic-Operation">
              <a
                href="#Atomic-Operation"
                class="headerlink"
                title="Atomic Operation"
              ></a
              >Atomic Operation
            </h3>
            <p>
              An atomic statement is an instruction that execute as a single
              indivisible unit.
            </p>
            <h4 id="Fine-Grained">
              <a
                href="#Fine-Grained"
                class="headerlink"
                title="Fine-Grained"
              ></a
              >Fine-Grained
            </h4>
            <p>Machine Level Intruction</p>
            <h4 id="Coarse-Grained">
              <a
                href="#Coarse-Grained"
                class="headerlink"
                title="Coarse-Grained"
              ></a
              >Coarse-Grained
            </h4>
            <p>A set of instruction execute in conjunction as a single unit.</p>
            <h3 id="Critical-Section">
              <a
                href="#Critical-Section"
                class="headerlink"
                title="Critical Section"
              ></a
              >Critical Section
            </h3>
            <p>
              It is <strong>code segment</strong> that
              <strong>accesses shared variables</strong> and has to be executed
              as an atomic action.
            </p>
            <h4 id="Preprotocol-x2F-Postprotocol">
              <a
                href="#Preprotocol-x2F-Postprotocol"
                class="headerlink"
                title="Preprotocol&#x2F;Postprotocol"
              ></a
              >Preprotocol&#x2F;Postprotocol
            </h4>
            <p>
              The pre-protocol and post-protocol are the sequences of
              instructions that the processes must execute to ensure that the
              instructions in the critical section are executed in compliance
              with the requirements.
            </p>
            <h3 id="Mutual-Exclusion">
              <a
                href="#Mutual-Exclusion"
                class="headerlink"
                title="Mutual Exclusion"
              ></a
              >Mutual Exclusion
            </h3>
            <p>
              <strong>Mutual exclusion</strong> is used to prevent
              <strong>race conditions</strong>. hence prevents simultaneous
              access to a shared resource.
              <strong>Only one of the processes can access</strong> the resource
              at same time and the others have to wait. When a process
              <strong>releases</strong> the exclusive access resource and
              another process was waiting, the waiting process will access the
              resource. Mutual exclusion allows creating coarse-grained atomic
              statements.
            </p>
            <h2 id="Abstractions">
              <a
                href="#Abstractions"
                class="headerlink"
                title="Abstractions"
              ></a
              >Abstractions
            </h2>
            <p>
              We use abstractions that allow us to abstract from details about
              system architecture.
            </p>
            <ol>
              <li>
                Each process is considered to
                <strong>run on its own processor</strong>.
              </li>
              <li>
                The relative speeds of each process are ignored, making it
                possible to consider only the sequences of instructions being
                executed.
              </li>
              <li>
                The sequences of execution of the
                <strong>atomic actions</strong> of all processes are considered
                to be
                <strong>interleaved in a single sequence</strong> completely
                without interference.
              </li>
            </ol>
            <p>
              All the abstractions can be summarized as the study of the
              sequences of interleaved execution of the atomic instructions of
              the sequential processes.
            </p>
            <h2 id="Thread">
              <a href="#Thread" class="headerlink" title="Thread"></a>Thread
            </h2>
            <p>
              They allow <strong>different control flows</strong> of a program
              <strong>coexist</strong> within the same process. They share
              resources like memory, but each has its
              <strong>own program counter, stack and local variables</strong>.
              They are sometimes called light processes, and many operating
              systems consider them the basic units planning. Operating Systems
              take care of scheduling threads and assigning to different
              processors as they’re available to run simultaneously and
              asynchronous with respect to each other. They share
              <strong>process stask</strong>, so everyone has access to them,
              allowing share data more efficiently.
            </p>
            <ul>
              <li>
                Create: When an instance of Thread is created (via new
                Thread(Runnable target)), it does not start executing right.
              </li>
              <li>
                Start: The threads start running when invokes the
                <strong>start()</strong> method of the Thread class.
              </li>
            </ul>
            <p>A program ends its execution when</p>
            <ul>
              <li>All its threads have finished their execution</li>
              <li>The <strong>System.exit()</strong> method is executed</li>
            </ul>
            <p>A thread ends its execution</p>
            <ul>
              <li>When all your statements have been executed</li>
              <li>
                When an unchecked exception is raised (RuntimeException) in the
                <strong>run()</strong> method
              </li>
              <li>User cancellation</li>
              <li>Timeout</li>
              <li>
                Events that trigger in other threads
                <ul>
                  <li>
                    Interruption with <strong>Thread.interrupt()</strong>
                    <ul>
                      <li>
                        We should periodically check if another thread has
                        interrupted this thread.
                      </li>
                      <li>
                        We will receive InterruptedException if the theread is
                        blocked.
                      </li>
                    </ul>
                  </li>
                  <li>etc…</li>
                </ul>
              </li>
            </ul>
            <p>
              When a thread finishs it should release resources appropriately,
              close connections, and leave objects in a stable state.
            </p>
            <p>
              If A thread wants to wait for another thread to end then invokes
              the <strong>join()</strong> method on the Thread class object that
              represents that thread.
            </p>
            <h3 id="Daemon">
              <a href="#Daemon" class="headerlink" title="Daemon"></a>Daemon
            </h3>
            <p>
              Daemon threads ends automatically when all non-daemon threads in a
              program have ended. A thread is a demon if the thread that creates
              it is also a demon. The <strong>isDaemon()</strong> and
              <strong>setDaemon()</strong> methods allow you to change this
              property of threads.
            </p>
            <h3 id="Priority">
              <a href="#Priority" class="headerlink" title="Priority"></a
              >Priority
            </h3>
            <p>
              The priority of a new thread is the same as the parent thread. The
              SO will respect the Java thread priority as far as possible.
            </p>
            <ul>
              <li>
                <strong>setPriority(int p)</strong>: Set the priority. Its value
                must be between Thread.MIN_PRIORITY and Thread.MAX_PRIORITY
              </li>
              <li>
                <strong>int getPriority()</strong>: Returns the priority of the
                thread.
              </li>
            </ul>
            <h3 id="Group">
              <a href="#Group" class="headerlink" title="Group"></a>Group
            </h3>
            <p>
              Threads can be grouped into groups represented by
              <strong>ThreadGroup</strong>. A ThreadGroup can have other groups
              of threads inside, creating a tree structure.
            </p>
            <ul>
              <li>Limit the priority of the threads that contain</li>
              <li>Manage certain properties of threads together</li>
            </ul>
            <h3 id="Properties">
              <a href="#Properties" class="headerlink" title="Properties"></a
              >Properties
            </h3>
            <ul>
              <li><strong>Thread.currentThread()</strong></li>
              <li><strong>.getName()</strong></li>
              <li><strong>isAlive()</strong></li>
              <li>
                <strong>getState()</strong>: Returns the state of the thread
                (new, executing, waiting …)
              </li>
            </ul>
            <h2 id="Conditional-Synchronization">
              <a
                href="#Conditional-Synchronization"
                class="headerlink"
                title="Conditional Synchronization"
              ></a
              >Conditional Synchronization
            </h2>
            <p>
              Occurs when one or more process must wait for a certain condition
              to be met to continue its execution. That condition must be set by
              another process.
            </p>
            <h3 id="Barrier-Synchronization">
              <a
                href="#Barrier-Synchronization"
                class="headerlink"
                title="Barrier Synchronization"
              ></a
              >Barrier Synchronization
            </h3>
            <p>
              <strong>Barrier</strong> is a conditional synchronization in which
              the processes have to wait for the rest of the processes to reach
              the same point in order to continue their execution.
            </p>
            <h2 id="Properties-of-Corrections">
              <a
                href="#Properties-of-Corrections"
                class="headerlink"
                title="Properties of Corrections"
              ></a
              >Properties of Corrections
            </h2>
            <p>
              We use them to judge if a concurrent algorithm is correct. They
              must be complied with in any possible intercalation of atomic
              instructions.
            </p>
            <h3 id="Safety">
              <a href="#Safety" class="headerlink" title="Safety"></a>Safety
            </h3>
            <ol>
              <li><strong>Mutual Exclusion</strong></li>
              <li>
                <strong>Absense of Deadlock</strong> (when multiples threads
                wait to each other and forms a cycle)
              </li>
            </ol>
            <h3 id="Liveness">
              <a href="#Liveness" class="headerlink" title="Liveness"></a
              >Liveness
            </h3>
            <p>
              We must avoid a parallel program enter a state in which it stops
              makeing forward progress.
            </p>
            <ol>
              <li><strong>Starvation</strong></li>
              <li><strong>Freedom from deadlock</strong></li>
              <li><strong>Absense of Livelock</strong></li>
            </ol>
            <h3 id="Absence-of-Unnecessary-Delays">
              <a
                href="#Absence-of-Unnecessary-Delays"
                class="headerlink"
                title="Absence of Unnecessary Delays"
              ></a
              >Absence of Unnecessary Delays
            </h3>
            <h3 id="Fairness">
              <a href="#Fairness" class="headerlink" title="Fairness"></a
              >Fairness
            </h3>
            <ol>
              <li>Linear Waiting</li>
              <li>FIFO</li>
              <li>Priority</li>
              <li>Random</li>
            </ol>
            <h2 id="Parallelism">
              <a href="#Parallelism" class="headerlink" title="Parallelism"></a
              >Parallelism
            </h2>
            <p>
              In the sequential programming you take a sequential algorithm and
              specify it as a sequence of steps. The parallelism is the study of
              which of these steps can run in parallel with each and how they
              should be coordinated. We use some notation here.
              <strong>fork</strong> when followed by a statement that causes the
              parent task to create a new child task to execute the body of the
              asynchronously with the remainder of the parent task statement,
              and <strong>join</strong> that specifies at the end of finish
              scope you’re guaranteed all asynchronous sub-tasks will have
              completed before can proceed. <strong>fork</strong> and
              <strong>join</strong> constructs may be arbitrarily nested.
            </p>
            <h3 id="Computation-Graph-CGs">
              <a
                href="#Computation-Graph-CGs"
                class="headerlink"
                title="Computation Graph (CGs)"
              ></a
              >Computation Graph (CGs)
            </h3>
            <p>
              We can use <strong>computation graph</strong> to model the task
              relationship between each task. The
              <strong>computation graph</strong> which model the
              <strong>execution of a parallel program</strong> as a
              <strong>partially ordered set</strong>. CGs consists of:
            </p>
            <ul>
              <li>
                A set of vertices or nodes, in which each node represents a
                <strong>step</strong> consisting of an arbitrary sequential
                computation.
              </li>
              <li>
                A set of directed edges that represent
                <strong>ordering constraints among steps</strong>.
              </li>
            </ul>
            <p>
              For fork join programs, it is useful to partition the edges into
              three cases:
            </p>
            <ol>
              <li>
                <strong>Continue edges</strong> that capture sequencing of steps
                within a task.
              </li>
              <li>
                <strong>Fork edges</strong> that connect a fork operation to the
                first step of child tasks.
              </li>
              <li>
                <strong>Join edges</strong> that connect the last step of a task
                to all join operations on that task.
              </li>
            </ol>
            <p>
              It helps us reason about which statements can execute in parallel.
              We ask “Is there a path of directed edges from one statement to
              another?”. So for example, there’s path from S2 and S4. So that
              tells us that S2 and S4 cannot run in parallel with each other.
              But between S2 and S3, we can see there’s a parallel execution
              that’s possible, because these’s no path of directed edges between
              S2 and S3.
            </p>
            <p>
              <strong>CGs</strong> can be used to define
              <strong>data races</strong>, an important class of bugs in
              parallel programs. We say that a data race occurs on location $L$
              in a computation graph, $G$, if there exist steps $S_1$ and $S_2$
              in $G$ such that there is no path of directed edges from $S_1$ to
              $S_2$ or from $S_2$ to $S_1$ in $G$, and both $S_1$ and $S_2$ read
              or write <em>L</em> (with at least one of the accesses being a
              write, since two parallel reads do not pose a problem).
            </p>
            <h4 id="Work-and-Span">
              <a
                href="#Work-and-Span"
                class="headerlink"
                title="Work and Span"
              ></a
              >Work and Span
            </h4>
            <p>
              CGs can also be used to reason about the
              <strong>performance</strong> of a parallel program as follows:
            </p>
            <ul>
              <li>
                Define <strong>WORK(G)</strong> to be the sum of the execution
                times of all nodes in CG <strong>G</strong>,
              </li>
              <li>
                Define <strong>SPAN(G)</strong> to be the length of a longest
                path in $G$, when adding up the execution times of all nodes in
                the path. The longest paths are known as
                <strong>critical paths</strong>.
              </li>
              <li>
                Given the above definitions of <strong>WORK</strong> and
                <strong>SPAN</strong>, we define the
                <strong>ideal parallelism</strong> of Computation Graph $G$ as
                the ratio, $\frac{WORK(G)}{SPAN(G)}$.
              </li>
              <li>
                The ideal parallelism is an upper limit on the speedup factor
                that can be obtained from parallel execution of nodes in
                computation graph <em>G</em>. Note that ideal parallelism is
                only a function of the parallel program, and does not depend on
                the actual parallelism available in a physical computer.
              </li>
            </ul>
            <p>
              So in this case, the <strong>work</strong> would be 1 plus 10 plus
              10 plus 1. That’s 22. And the <strong>span</strong> which is 12 in
              this case. So the <strong>ideal parallelism</strong> is 2
            </p>
            <p><img src="computation-graph.png" alt="Computation Graph" /></p>
            <h4 id="Time-of-execution-and-Speedup">
              <a
                href="#Time-of-execution-and-Speedup"
                class="headerlink"
                title="Time of execution and Speedup"
              ></a
              >Time of execution and Speedup
            </h4>
            <p>
              We defined $T_{P}$ as the execution time of a CG on $P$
              processors. The definition of the execution time on $P$ processors
              actually depends on the schedule. Suppose we have greedy schedule
              in which a processor is not permitted to be idle if a CG node is
              available to be scheduled on it. Given any $P$ processors, $Span
              &#x3D; T_{\infty} \le T_P \le T_{1} &#x3D; Work$. We then defined
              the parallel speedup for a given schedule of a CG on $P$
              processors as $\text{Speedup}(P) &#x3D; \frac{T_1}{T_P}$​ and
              observed that $\text{Speedup}(P)$ must be less than the number of
              processors $P$, and also less than the ideal parallelism,
              $\frac{Work}{Span}$. Our goal in parallel algorithms is to
              generate computation graphs with ideal parallelism that’s much
              larger than the number of processors that you have, so that you
              have the flexibility of running that parallel program on numerous
              processors.
            </p>
            <h4 id="Amdahl’s-Law">
              <a
                href="#Amdahl’s-Law"
                class="headerlink"
                title="Amdahl’s Law"
              ></a
              >Amdahl’s Law
            </h4>
            <p>
              Let’s assume that $q$ is the fraction of $WORK$ in a parallel
              program that must be executed <strong>sequentially</strong>, the
              <strong>span</strong> must be at least $q \cdot \text{Work}$, then
              the maximum speedup that can be obtained for that program for any
              number of processors $P$ is going to be bounded over by
              $\text{Speedup}(P) \le \frac{1}{q}$.
            </p>
            <p>
              This observation follows directly from a lower bound on parallel
              execution time $\text{SPAN}(G) \le T_p$. If fraction $q$ of
              $WORK(G)$ is sequential, it must be the case that $q \cdot
              \text{WORK}(G) \le \text{Span}(G) \le T_p$. Therefore,
              $\text{Speedup}(P) &#x3D; \frac{T_1}{T_P} \le
              \frac{\text{WORK}(G)}{q \cdot \text{WORK}(G)} &#x3D; \frac{1}{q}$
              since $T_1​ &#x3D; WORK(G)$ for greedy schedulers.
            </p>
            <p>
              What they mean is that there’s some part of the computation that’s
              being done inherently sequentially that is going to limit the
              speedup. Amdahl’s Law reminds us to watch out for sequential
              bottlenecks both when designing parallel algorithms and when
              implementing programs on real machines. Even if $q&#x3D;10%$ then
              best possible speedup must be $\le 10 &#x3D; \frac{1}{q}$,
              regardless of the number of processors available.
            </p>
            <h3 id="Forkjoin">
              <a href="#Forkjoin" class="headerlink" title="Forkjoin"></a
              >Forkjoin
            </h3>
            <p>
              Parallel versions of classic algorithms divide and conquer. Divide
              a task into smaller sub-tasks that can be executed concurrently.
            </p>
            <h4 id="Fork">
              <a href="#Fork" class="headerlink" title="Fork"></a>Fork
            </h4>
            <p>
              A task split itself into smaller subtasks a task into smaller
              sub-tasks which can be executed concurrently.
            </p>
            <p><img src="fork.png" alt="Fork" /></p>
            <h3 id="Join">
              <a href="#Join" class="headerlink" title="Join"></a>Join
            </h3>
            <p>
              When a task has split itself up into subtasks, the task waits
              until the subtasks have finished executing. Once the subtasks have
              finished executing, the task may join all the results into one
              result.
            </p>
            <p><img src="join.png" alt="Join" /></p>
            <h3 id="ForkJoinPool">
              <a
                href="#ForkJoinPool"
                class="headerlink"
                title="ForkJoinPool"
              ></a
              >ForkJoinPool
            </h3>
            <p>
              ForkJoinPool is similar to the ExecutorService but designed to
              work efficiently with fork&#x2F;join task division.
            </p>
            <ul>
              <li>
                <strong>new ForkJoinPool()</strong>: The default constructor
                will create a pool with as many threads as there are processors
                available.
              </li>
              <li>
                <strong>new ForkJoinPool(int parallelism)</strong>: We can also
                specify the number of threads
              </li>
              <li>
                <strong>ForkJoinPool.commonPool()</strong>: return a common pool
              </li>
            </ul>
            <p>
              The order matter, we should create first with
              <strong>fork()</strong> and then <strong>join()</strong>.
            </p>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/9e9c769b30e3eb9c21e449b9b641a020250e76fb/rubbish/src/main/java/concurrente/Tema5.java#L193-L221"
                >Fork Join Sum</a
              >
            </p>
            <p>
              The idea is that you perform all the computations in L and R in
              parallel, wait for them to complete and then proceed next.
            </p>
            <h3 id="MapReduce">
              <a href="#MapReduce" class="headerlink" title="MapReduce"></a
              >MapReduce
            </h3>
            <p>The main idea of MapReduce is similar to Fork&#x2F;Join.</p>
            <ul>
              <li>
                Reduce task size and assign them to multiple computers
                concurrently.
              </li>
              <li>
                The results are retrieved and integrated to create the final
                result.
              </li>
            </ul>
            <h4 id="Map">
              <a href="#Map" class="headerlink" title="Map"></a>Map
            </h4>
            <p>
              You select one data set and transform it into another, where each
              element is divided into key value pairs.
            </p>
            <h4 id="Reduce">
              <a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce
            </h4>
            <p>
              Select Map output as input and combine those pairs into smaller
              sets of tuples
            </p>
            <p><img src="map-reduce.png" alt="Map Reduce" /></p>
            <h2 id="Future">
              <a href="#Future" class="headerlink" title="Future"></a>Future
            </h2>
            <p>
              A Java Future represents the result of an asynchronous
              computation. When the asynchronous task is created, a Java Future
              object is returned. This Future object functions as a handle to
              the result of the asynchronous task. Once the asynchronous task
              completes, the result can be accessed via the Future object
              returned when the task was started.
            </p>
            <h3 id="Get-Result">
              <a href="#Get-Result" class="headerlink" title="Get Result"></a
              >Get Result
            </h3>
            <p>
              As mentioned earlier, a Java <strong>Future</strong> represents
              the result of an asynchronous task. To obtain the result, you call
              <strong>get()</strong> methods on the Future. If you call the
              get() method before the asynchronous task has completed, the get()
              method will block until the result is ready.
            </p>
            <h3 id="Functional-Parallelism">
              <a
                href="#Functional-Parallelism"
                class="headerlink"
                title="Functional Parallelism"
              ></a
              >Functional Parallelism
            </h3>
            <p>
              The future is carefully defined to avoid the possibility of a race
              condition and it is suited for functional parallelism. So if we
              write our tasks as pure functions calls like $F(X)$ so that if you
              call $F(X)$ multiple times with the same input, you will always
              get the same output $Y$. From that observation, we see that if
              pure function $G$ and pure function $H$ only depend on the output
              of $F$ then these two computations could actually execute in
              either order. Future of $F$ act as a wrapper of the output value
              $F$ and it is final. If we pass the future of output value from
              $F$, then even if $G$ and $F$ run in parallel when they actually
              need the output value from $F$ they will get blocked and wait
              until the value is available. From the computation graph
              perspective, the join edges arise from the get operations of
              future object.
            </p>
            <p><img src="Future-Get.png" alt="Future Get" /></p>
            <h2 id="Memorization">
              <a
                href="#Memorization"
                class="headerlink"
                title="Memorization"
              ></a
              >Memorization
            </h2>
            <p>
              The memoization pattern lends itself easily to parallelization
              using futures by modifying the memoized data structure X to store
              Future&lt;X&gt;
            </p>
            <h2 id="Determinism">
              <a href="#Determinism" class="headerlink" title="Determinism"></a
              >Determinism
            </h2>
            <h3 id="Functional-Determinism">
              <a
                href="#Functional-Determinism"
                class="headerlink"
                title="Functional Determinism"
              ></a
              >Functional Determinism
            </h3>
            <p>
              A parallel program is said to be
              <strong>functionally deterministic</strong> if it always computes
              the same answer when given the same input.
            </p>
            <h3 id="Structural-Determinism">
              <a
                href="#Structural-Determinism"
                class="headerlink"
                title="Structural Determinism"
              ></a
              >Structural Determinism
            </h3>
            <p>
              The idea behind <strong>structural determinism</strong> is it
              always computes the same computation graph, when given the same
              input.
            </p>
            <h3 id="Data-Race">
              <a href="#Data-Race" class="headerlink" title="Data Race"></a>Data
              Race
            </h3>
            <p>
              A data race is an unsafe access to the same piece of data from two
              independently parallel executions without some mechanism in place
              to avoid the conflict. The presence of data races often leads to
              functional and&#x2F;or structural nondeterminism because a
              parallel program with data races may exhibit different behaviors
              for the same input, depending on the relative scheduling and
              timing of memory accesses involved in a data race. In general, the
              <strong
                >absence of data races is not sufficient to guarantee
                determinism</strong
              >. However, all the parallel constructs <strong>fork</strong>,
              <strong>join</strong>, <strong>future</strong> were carefully
              selected to ensure if a parallel program is written using these
              constructs and is guaranteed to be
              <strong>data-race freedom</strong> that’s the
              <strong>absence of data races</strong>, then it implies both
              <strong>functional determinism</strong> and
              <strong>structural determinism</strong>.
            </p>
            <h3 id="Nondeterministic">
              <a
                href="#Nondeterministic"
                class="headerlink"
                title="Nondeterministic"
              ></a
              >Nondeterministic
            </h3>
            <p>
              Furthermore, there may be cases of
              <strong>nondeterministic</strong> programs in which different
              executions with the same input may generate different outputs, but
              all the outputs may be <strong>acceptable</strong> in the context
              of the application.
            </p>
            <h2 id="Parallelism-Loop">
              <a
                href="#Parallelism-Loop"
                class="headerlink"
                title="Parallelism Loop"
              ></a
              >Parallelism Loop
            </h2>
            <p>
              The most general way express parallelism loop is to think of each
              iteration of a parallel loop as an <strong>fork</strong> task,
              with a <strong>join</strong> construct encompassing all
              iterations.
            </p>
            <h3 id="Barriers-in-Parallel-Loops">
              <a
                href="#Barriers-in-Parallel-Loops"
                class="headerlink"
                title="Barriers in Parallel Loops"
              ></a
              >Barriers in Parallel Loops
            </h3>
            <p>
              The barriers extend a parallel loop by dividing its execution into
              a sequence of <strong>phases</strong>. While it may be possible to
              write a separate <strong>parallelism loop</strong> for each phase,
              it is both more convenient and more efficient to instead insert
              barriers in a single <strong>parallelism loop</strong>.
            </p>
            <h3 id="Iteration-Grouping">
              <a
                href="#Iteration-Grouping"
                class="headerlink"
                title="Iteration Grouping"
              ></a
              >Iteration Grouping
            </h3>
            <p>
              We observed that this approach creates <strong>n</strong> tasks,
              one per <strong>parallelism loop</strong> iteration, which is
              wasteful when <strong>n</strong> is much larger than the number of
              available processor cores. To address this problem, we learned a
              common tactic used in practice that is referred to as
              <strong>iteration grouping</strong>, and focuses on reducing the
              number of tasks created to be closer to the number of processor
              cores, to reduce the overhead of parallel execution. There are two
              well known approaches for iteration grouping:
              <strong>block</strong> and <strong>cyclic</strong>. The
              <strong>block</strong> form maps consecutive iterations to the
              same group, whereas <strong>cyclic</strong> maps iterations in the
              same congruence class $i \mod ng$ to the same group.
            </p>
            <h2 id="Phaser">
              <a href="#Phaser" class="headerlink" title="Phaser"></a>Phaser
            </h2>
            <p>
              <strong>Barrier</strong> may take some computation time and it is
              ideal if we can overlap the computation with other computation and
              the <strong>span</strong> can be lower. So
              <strong>phaser</strong> come in,
              <strong>arriveAndAwaitAdvance</strong> can be used to implement a
              barrier through <strong>phaser</strong> object. To facilitate the
              <strong>split-phase barrier</strong> (also known as a
              <strong>fuzzy barrier</strong>) we use two separate APIs from Java
              Phaser class — <strong>.arrive()</strong> and
              <strong>awaitAdvance()</strong>. Together these two APIs form a
              barrier, but we now have the freedom to insert a computation to be
              performed in parallel with the barrier between the two calls.
            </p>
            <h3
              id="Point-to-Point-Synchronization-with-Phasers-and-Dataflow-Synchronization"
            >
              <a
                href="#Point-to-Point-Synchronization-with-Phasers-and-Dataflow-Synchronization"
                class="headerlink"
                title="Point-to-Point Synchronization with Phasers and Dataflow Synchronization"
              ></a
              >Point-to-Point Synchronization with Phasers and Dataflow
              Synchronization
            </h3>
            <p>
              We can use multiple phasers to create the dependencies graph
              between them.
            </p>
            <h3 id="Pipeline-Parallelism">
              <a
                href="#Pipeline-Parallelism"
                class="headerlink"
                title="Pipeline Parallelism"
              ></a
              >Pipeline Parallelism
            </h3>
            <p>
              Let $n$ be the number of input items and $p$ the number of stages
              in the pipeline, $WORK &#x3D; n × p$_ is the total work that must
              be done for all data items, and $SPAN &#x3D; n + p − 1$ for the
              pipeline. Thus, the ideal parallelism is $WORK&#x2F;SPAN &#x3D; np
              &#x2F; (n + p − 1)$. When $n$ is much larger than $p$ then the
              ideal parallelism approaches $PAR &#x3D; p$ in the limit. The
              synchronization required for pipeline parallelism can be
              implemented as follows
            </p>
            <pre><code>// Code for pipeline stage i
while ( there is an input to be processed ) &#123;
  // wait for previous stage, if any 
  if (i &gt; 0) ph[i - 1].awaitAdvance(); 
  
  process input;
  
  // signal next stage
  ph[i].arrive();
&#125;
</code></pre>
            <h2 id="Producer-x2F-Consumer">
              <a
                href="#Producer-x2F-Consumer"
                class="headerlink"
                title="Producer&#x2F;Consumer"
              ></a
              >Producer&#x2F;Consumer
            </h2>
            <ul>
              <li><strong>Producer</strong>: produces a message.</li>
              <li>
                <strong>Consumer</strong>: consumes and remove the message.
              </li>
              <li>Each producer generates a single data each time.</li>
              <li>A consumer can only consume one data.</li>
              <li>All the product will be process.</li>
              <li>You cannot consume the same product twice.</li>
            </ul>
            <h2 id="Reader-x2F-Writer">
              <a
                href="#Reader-x2F-Writer"
                class="headerlink"
                title="Reader&#x2F;Writer"
              ></a
              >Reader&#x2F;Writer
            </h2>
            <p>
              Some threads may read and some may write, with the constraint that
              no thread may access the shared resource for either reading or
              writing while another thread is in the act of writing to it.
            </p>
            <ul>
              <li>
                <strong>Readers</strong>: Processes which are not required to
                exclude one another. Any number of readers may simultaneously
                read the resource.
              </li>
              <li>
                <strong>Writers</strong>: Processes which exclude all the other
                readers when writing a resource. As long as a reader is reading,
                no writer can access the DB.
              </li>
              <li>
                Requirement: There may be several writers working, although
                these will have to be synchronized so that the writing is
                carried out one by one
              </li>
              <li>
                Requirement: Writers have priority. No reader can access the DB
                when there are writers who wish to do so.
              </li>
            </ul>
            <h2 id="Dining-Philosopher-Problem">
              <a
                href="#Dining-Philosopher-Problem"
                class="headerlink"
                title="Dining Philosopher Problem"
              ></a
              >Dining Philosopher Problem
            </h2>
            <ul>
              <li>
                Preprotocol: The philosopher sits down in front of his plate and
                takes the forks on either side of his plate one by one.
              </li>
              <li>Critical Section: Eat</li>
              <li>
                Postprotocol: When finished, leave the two forks in their
                original position
              </li>
              <li>
                Requirement: Every philosopher who eats, at some point is
                satisfied and ends
              </li>
              <li>
                Requirement: A philosopher can only eat when he has both forks
              </li>
              <li>
                Requirement: The forks are picked up and put down one by one
              </li>
              <li>
                Requirement: Two philosophers cannot have the same fork
                simultaneously
              </li>
              <li>
                Requirement: If several philosophers try to eat at the same
                time, one of them must succeed
              </li>
              <li>
                Requirement: In the absence of competition, a philosopher who
                wants to eat must do so without unnecessary delay.
              </li>
            </ul>
            <h3 id="Deadlock">
              <a href="#Deadlock" class="headerlink" title="Deadlock"></a
              >Deadlock
            </h3>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/194f39a2c674b803dad8fb64ff6897bd271fe955/judge/src/main/java/geeksforgeeks/concurrent/DiningPhilosopher.java#L18-L44"
                >Deadlock</a
              >
            </p>
            <h3 id="Livelock">
              <a href="#Livelock" class="headerlink" title="Livelock"></a
              >Livelock
            </h3>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/194f39a2c674b803dad8fb64ff6897bd271fe955/judge/src/main/java/geeksforgeeks/concurrent/DiningPhilosopher.java#L46-L81"
                >Livelock</a
              >
            </p>
            <h3 id="Solution">
              <a href="#Solution" class="headerlink" title="Solution"></a
              >Solution
            </h3>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/194f39a2c674b803dad8fb64ff6897bd271fe955/judge/src/main/java/geeksforgeeks/concurrent/DiningPhilosopher.java#L83-L112"
                >DiningPhilosopher solution</a
              >
            </p>
            <h2 id="Volatile">
              <a href="#Volatile" class="headerlink" title="Volatile"></a
              >Volatile
            </h2>
            <p>
              Reading and writing <strong>simple type</strong> variable are
              atomic instructions, unless the variable is of type
              <strong>long</strong> or <strong>double</strong>. For modern
              computer, usually there is a cache for each processor. Although
              the change to primitive variable is atomic, the write is not
              neccesary <strong>visible</strong> to other processor. To do so,
              you have to declare the variable as
              <strong>volatile</strong> which guarantee the visibility for all
              the primitive types for all processors.
            </p>
            <p>
              It is not necessary to use volatile if the threads use some
              synchronization method. If the shared resources are mutually
              exclusive with semaphore, the correct values are guaranteed to be
              read. If one process writes an resource and unlocks another
              process, the other process will read the written value.
            </p>
            <h2 id="Busy-Waiting">
              <a
                href="#Busy-Waiting"
                class="headerlink"
                title="Busy Waiting"
              ></a
              >Busy Waiting
            </h2>
            <p>
              When we use volatile variable for synchronization. Busy waiting is
              very inefficient and generally should be avoided.
            </p>
            <h3 id="Dekker’s-algorithm">
              <a
                href="#Dekker’s-algorithm"
                class="headerlink"
                title="Dekker’s algorithm"
              ></a
              >Dekker’s algorithm
            </h3>
            <h4 id="Mandatory-Alternation-Unnecessary-Delays">
              <a
                href="#Mandatory-Alternation-Unnecessary-Delays"
                class="headerlink"
                title="Mandatory Alternation - Unnecessary Delays"
              ></a
              >Mandatory Alternation - Unnecessary Delays
            </h4>
            <p>
              A turn variable is used that indicates the process that can enter
              the critical section.
            </p>
            <pre><code>private static volatile int turn;

private static void p1() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        while (turno != 1);
        
        /* Critical Section */

        /* Postprotocol */
        turn = 2;
        
        /* No critical Section */
    &#125;
&#125;

private static void p2() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        while (turn != 2);

        /* Critical Section */

        /* Postprotocol */
        turn = 1;

        /* No critical Section */
    &#125;
&#125;
</code></pre>
            <h4 id="No-Mutual-Exclusion">
              <a
                href="#No-Mutual-Exclusion"
                class="headerlink"
                title="No Mutual Exclusion"
              ></a
              >No Mutual Exclusion
            </h4>
            <p>
              We can use a boolean variable for each process that indicates if
              said process is in the critical section.
            </p>
            <pre><code>private static volatile boolean p1cs;
private static volatile boolean p2cs;

private static void p1() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        while (p2cs);
        p1cs = true;

        /* Critical Section */

        /* Postprotocol */
        p1cs = false;

        /* No critical Section */
    &#125;
&#125;

private static void p2() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        while (p1cs);
        p2cs = true;

        /* Critical Section */

        /* Postprotocol */
        p2cs = false;
        
        /* No critical Section */
    &#125;
&#125;
</code></pre>
            <p>
              Both processes can execute the critical section instructions at
              the same time.
            </p>
            <h4 id="Deadlock-1">
              <a href="#Deadlock-1" class="headerlink" title="Deadlock"></a
              >Deadlock
            </h4>
            <p>
              Let we request the access before we enter the critical section.
            </p>
            <pre><code>private static volatile boolean intent_p1;
private static volatile boolean intent_p2;

private static void p1() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        intent_p1 = true;
        while (intent_p2);

        /* Critical Section */
        
        /* Postprotocol */
        intent_p1 = false;

        /* No critical Section */
    &#125;
&#125;

private static void p2() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        intent_p2 = true;
        while (intent_p1);

        /* Critical Section */
        
        /* Postprotocol */
        intent_p2 = false;

        /* No critical Section */
    &#125;
&#125;
</code></pre>
            <h4 id="Starvation-Livelock-No-Mutual-Exclusion">
              <a
                href="#Starvation-Livelock-No-Mutual-Exclusion"
                class="headerlink"
                title="Starvation - Livelock - No Mutual Exclusion"
              ></a
              >Starvation - Livelock - No Mutual Exclusion
            </h4>
            <p>
              Yields your right to enter the critical section if you discover
              that there is competition with another process.
            </p>
            <pre><code>private static volatile boolean intent_p1;
private static volatile boolean intent_p2;

private static void p1() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        intent_p1 = true;
        while (intent_p2) &#123;
            intent_p1 = false;
            intent_p2 = true;
        &#125;

        /* Critical Section */
        
        /* Postprotocol */
        intent_p1 = false;

        /* No critical Section */
    &#125;
&#125;

private static void p2() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        intent_p2 = true;
        while (intent_p1) &#123;
            intent_p2 = false;
            intent_p1 = true;
        &#125;

        /* Critical Section */
        
        /* Postprotocol */
        intent_p2 = false;

        /* No critical Section */
    &#125;
&#125;
</code></pre>
            <p>
              Alternatively giving the right and never enter the critical
              section.
            </p>
            <h4 id="Final-Solution">
              <a
                href="#Final-Solution"
                class="headerlink"
                title="Final Solution"
              ></a
              >Final Solution
            </h4>
            <p>It is a combination of the 1st and 4th approach.</p>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/31d59e0182225178c7eec5631b3661adf3cf650a/judge/src/main/java/geeksforgeeks/concurrent/DekkerAlgorithm.java"
                >Dekker’s algorithm</a
              >
            </p>
            <h2 id="Semaphore">
              <a href="#Semaphore" class="headerlink" title="Semaphore"></a
              >Semaphore
            </h2>
            <p>
              A semaphore is a Abstract Data Type that support two operations.
            </p>
            <ol>
              <li>
                The <strong>acquire()</strong> method decreases the number of
                semaphore permissions or hangs until someone release a
                permission when is zero.
              </li>
              <li>
                The <strong>release()</strong> method increases the number of
                semaphore permissions. If there are blocked processes at the
                semaphore, unblock one of them FIFO or Randomly and continues
                its execution
              </li>
            </ol>
            <ul>
              <li>
                <strong>acquire()</strong>: Acquires the given number of permits
                from this semaphore, blocking until all are available, or the
                thread is interrupted.
              </li>
              <li>
                <strong>acquireUninterruptibly()</strong>: Acquires a permit
                from this semaphore, blocking until one is available.
              </li>
              <li>
                <strong>tryAcquire()</strong>: Acquires a permit from this
                semaphore, only if one is available at the time of invocation.
                return false if it is unavailable.
              </li>
              <li>
                <strong>tryAcquire(long timeout, TimeUnit unit)</strong>:
                Acquires a permit from this semaphore, if one becomes available
                within the given waiting time and the current thread has not
                been interrupted, return false if no one is available within the
                timeout.
              </li>
              <li>
                <strong>drainPermits()</strong>: Acquires and returns all
                permits that are immediately available.
              </li>
              <li>
                <strong>getQueueLength()</strong>: Returns an estimate of the
                number of threads waiting to acquire.
              </li>
              <li>
                <strong>hasQueuedThreads()</strong>: Queries whether any threads
                are waiting to acquire.
              </li>
            </ul>
            <h3 id="Development-Process">
              <a
                href="#Development-Process"
                class="headerlink"
                title="Development Process"
              ></a
              >Development Process
            </h3>
            <ol>
              <li>
                Define process architecture (number of processes and type)
              </li>
              <li>Sequential implementation</li>
              <li>
                Determine sync points in code
                <ol>
                  <li>Conditional Synchronization or Mutual Exclusion</li>
                  <li>Number of Semaphores Needed</li>
                  <li>Can all processes be blocked together?</li>
                  <li>Can any of them be unlocked?</li>
                </ol>
              </li>
              <li>
                Define necessary semaphores to control synchronization and write
                acquire() and release()
              </li>
              <li>
                Variable management
                <ol>
                  <li>Initialization of boolean and counters</li>
                  <li>Under Mutual Exclusion if they are shared</li>
                </ol>
              </li>
            </ol>
            <h3 id="Conditional-Synchronization-With-Semaphore">
              <a
                href="#Conditional-Synchronization-With-Semaphore"
                class="headerlink"
                title="Conditional Synchronization With Semaphore"
              ></a
              >Conditional Synchronization With Semaphore
            </h3>
            <pre><code>private static volatile boolean continue = false;
private static Semaphore semaphore = new Semaphore(0);

private static void p1() &#123;
    /* task p1.1 */
    continue = true;
    /* task p1.2 */
&#125;

private static void p2() &#123;
    /* task p2.1 */
    while (!continue);
    /* task p2.2 */
&#125;

private static void p1_semaphore() &#123;
    /* task p1.1 */
    semaphore.release();
    /* task p1.2 */
&#125;

private static void p2_semaphore() &#123;
    /* task p2.1 */
    semaphore.acquire();
    /* task p2.2 */
&#125;
</code></pre>
            <h3 id="Mutual-Exclusion-with-Semaphore">
              <a
                href="#Mutual-Exclusion-with-Semaphore"
                class="headerlink"
                title="Mutual Exclusion with Semaphore"
              ></a
              >Mutual Exclusion with Semaphore
            </h3>
            <pre><code>private static Semaphore sem = new Semaphore(1);

private static void p() throws InterruptedException &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        sem.acquire();

        /* Critical Section */

        /* Postprotocol */
        sem.release();

        /* No Critical Section */
    &#125;
&#125;
</code></pre>
            <h3 id="Barrier-with-Semaphore-First-Example">
              <a
                href="#Barrier-with-Semaphore-First-Example"
                class="headerlink"
                title="Barrier with Semaphore First Example"
              ></a
              >Barrier with Semaphore First Example
            </h3>
            <p>
              The processes have to wait for everyone to have written the letter
              1 before writing the 2.
            </p>
            <h4 id="First-Incorrect-Approach">
              <a
                href="#First-Incorrect-Approach"
                class="headerlink"
                title="First Incorrect Approach"
              ></a
              >First Incorrect Approach
            </h4>
            <pre><code>private static volatile int nProcess = 0;
private static Semaphore sem = Semaphore(0);
private static void p() throws InterruptedException&#123;
    System.out.println(&quot;1&quot;);
    nProcess += 1;
    if (nProcess &lt; N_PROCESSES) sem.acquire();
    else for (int i = 0; i &lt; N_PROCESSES - 1; i++) sem.release();
    System.out.println(&quot;2&quot;);
&#125;
</code></pre>
            <p><strong>nProcess</strong> is not under mutual exclusion</p>
            <h4 id="Second-Incorrect-Approach">
              <a
                href="#Second-Incorrect-Approach"
                class="headerlink"
                title="Second Incorrect Approach"
              ></a
              >Second Incorrect Approach
            </h4>
            <pre><code>private static volatile int nProcess = 0;
private static Semaphore sem = Semaphore(0);
private static Semaphore lock = Semaphore(1);
private static void p() throws InterruptedException&#123;
    System.out.println(&quot;1&quot;);
    lock.acquire();
    nProcess += 1;
    lock.release();
    if (nProcess &lt; N_PROCESSES) sem.acquire();
    else for (int i = 0; i &lt; N_PROCESSES - 1; i++) sem.release();
    System.out.println(&quot;2&quot;);
&#125;
</code></pre>
            <p>
              Query nProcess outside the mutual exclusion may result multiple
              processes release the sem which will leave the sem in the
              unpredictable state.
            </p>
            <h4 id="First-Correct-Approach">
              <a
                href="#First-Correct-Approach"
                class="headerlink"
                title="First Correct Approach"
              ></a
              >First Correct Approach
            </h4>
            <pre><code>private static volatile int nProcess = 0;
private static Semaphore sem = Semaphore(0);
private static Semaphore lock = Semaphore(1);
private static void p() throws InterruptedException&#123;
    System.out.println(&quot;1&quot;);
    lock.acquire();
    nProcess += 1;
    if (nProcess &lt; N_PROCESSES) &#123;
        lock.release();
        sem.acquire();
    &#125;
    else &#123;
        lock.release();
        for (int i = 0; i &lt; N_PROCESSES - 1; i++) &#123;
            sem.release();
        &#125;
    &#125;
    System.out.println(&quot;2&quot;);
&#125;
</code></pre>
            <p>We release after the query</p>
            <h4 id="Second-Correct-Approach">
              <a
                href="#Second-Correct-Approach"
                class="headerlink"
                title="Second Correct Approach"
              ></a
              >Second Correct Approach
            </h4>
            <pre><code>private static volatile int nProcess = 0;
private static Semaphore sem = Semaphore(0);
private static Semaphore lock = Semaphore(1);
private static void p() throws InterruptedException&#123;
    System.out.println(&quot;1&quot;);
    lock.acquire();
    nProcess += 1;
    if (nProcess == N_PROCESSES) &#123;
        for (int i = 0; i &lt; N_PROCESSES; i++) &#123;
            sem.release();
        &#125;
    &#125;
    lock.release(); 
    sem.acquire();
    System.out.println(&quot;2&quot;);
&#125;
</code></pre>
            <h3 id="Barrier-with-Semaphore">
              <a
                href="#Barrier-with-Semaphore"
                class="headerlink"
                title="Barrier with Semaphore"
              ></a
              >Barrier with Semaphore
            </h3>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/a286df7d1569887f7adbafd4d2aec83ff0ee4c3a/core/src/main/java/core/concurrent/SemaphoreBarrier.java"
                >SemaphoreBarrier</a
              >
            </p>
            <h3 id="K-Mutual-Exclusion">
              <a
                href="#K-Mutual-Exclusion"
                class="headerlink"
                title="K Mutual Exclusion"
              ></a
              >K Mutual Exclusion
            </h3>
            <p>
              When the number of processes that can run the critical section at
              once is N &gt; 1, it is implemented with semaphore assigning
              initially a K value at the semaphore.
            </p>
            <pre><code>private static final int N;
private static final Semaphore sem = new Semaphore(N);

private static void p() throws InterruptedException &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        /* Preprotocol */
        sem.acquire();
        
        /* Critical Section */

        /* Postprotocol */
        sem.release();
        
        /* No Critical Section */
    &#125;
&#125;
</code></pre>
            <h3 id="Buffer">
              <a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer
            </h3>
            <p>In producer-consumer problem</p>
            <ul>
              <li>
                A buffer will be used to store the data produced before being
                consumed
              </li>
              <li>Producer should block if the buffer is full</li>
              <li>Consumers should block when they have no data to consume.</li>
              <li>Control variables must be under mutual exclusion</li>
            </ul>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/e34b48b84814921fe2947e9123a1d138227c4762/core/src/main/java/core/concurrent/SemaphoreArrayBlockingQueue.java"
                >SemaphoreArrayBlockingQueue</a
              >
            </p>
            <h3 id="Reader-x2F-Writer-With-Semaphore">
              <a
                href="#Reader-x2F-Writer-With-Semaphore"
                class="headerlink"
                title="Reader&#x2F;Writer With Semaphore"
              ></a
              >Reader&#x2F;Writer With Semaphore
            </h3>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/c47e3f3e58e612ed98dbd1f1cb5d2a53c26f8350/core/src/main/java/core/concurrent/Semaphore_DB_Lock.java"
                >Semaphore_DB_Lock</a
              >
            </p>
            <h2 id="Lock">
              <a href="#Lock" class="headerlink" title="Lock"></a>Lock
            </h2>
            <h3 id="Structured-locks">
              <a
                href="#Structured-locks"
                class="headerlink"
                title="Structured locks"
              ></a
              >Structured locks
            </h3>
            <p>
              Structured locks can be used to enforce mutual exclusion and avoid
              data races. A major benefit of structured locks is that their
              acquire and release operations are implicit, since these
              operations are automatically performed by the Java runtime
              environment when entering and exiting the scope of a
              <strong>synchronized</strong> statement or method, even if an
              exception is thrown in the middle.
            </p>
            <p>
              The synchronized keyword is put into the method and current object
              acts as a lock. Synchronized statements and methods are reentrant.
              If a thread that has acquired the lock in a synchronized method,
              calls another synchronized method, picks up the lock again, it
              does not stay locked. This allows the reuse of synchronized
              methods. But they have some limitations.
            </p>
            <ul>
              <li>
                A synchronized block makes no guarantees about the sequence in
                which threads waiting to entering it are granted access.
              </li>
              <li>
                Mutual exclusion cannot be acquired in one method and released
                in another.
              </li>
              <li>
                You cannot specify a maximum waiting time to acquire the lock.
              </li>
              <li>You cannot create an extended mutual exclusion.</li>
            </ul>
            <h4 id="Synchronized-Block">
              <a
                href="#Synchronized-Block"
                class="headerlink"
                title="Synchronized Block"
              ></a
              >Synchronized Block
            </h4>
            <pre><code>private static int x = 0;
private static Object lock = new Object();

private static void inc() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        synchronized (lock) &#123;
            x = x + 1;
        &#125;
    &#125;
&#125;

private static void dec() &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        synchronized (lock) &#123;
            x = x - 1;
        &#125;
    &#125;
&#125;
</code></pre>
            <h4 id="Synchronized-Method">
              <a
                href="#Synchronized-Method"
                class="headerlink"
                title="Synchronized Method"
              ></a
              >Synchronized Method
            </h4>
            <pre><code>public class Counter &#123;
    private int x = 0;
    
    public synchronized void inc() &#123;
        x = x + 1;
    &#125;
    
    public int getValue() &#123;
        return x;
    &#125;
&#125;
</code></pre>
            <h3 id="Lock-Interface">
              <a
                href="#Lock-Interface"
                class="headerlink"
                title="Lock Interface"
              ></a
              >Lock Interface
            </h3>
            <p>
              <strong>java.util.concurrent.locks.Lock</strong> provide explicit
              <strong>lock()</strong> and <strong>unlock()</strong> operations
              on unstructured locks can be used to support a hand-over-hand
              locking pattern that implements a non-nested pairing of
              lock&#x2F;unlock operations which cannot be achieved with
              <strong>synchronized</strong> statements&#x2F;methods.
            </p>
            <pre><code>lock.lock();
try &#123;
    /* Critical Section */
&#125; finally &#123;
    lock.unlock()
&#125;
</code></pre>
            <ul>
              <li>
                <strong>lock()</strong>: locks the Lock instance if possible. If
                the Lock instance is already locked, the thread calling lock()
                is blocked until the Lock is unlocked.
              </li>
              <li>
                <strong>lockInterruptibly()</strong>: Acquires the lock unless
                the current thread is interrupted.
              </li>
              <li>
                <strong>tryLock()</strong>: Acquires the lock only if it is not
                held by another thread at the time of invocation.
              </li>
              <li>
                <strong>tryLock(long time, TimeUnit unit)</strong>: Acquires the
                lock if it is not held by another thread within the given
                waiting time and the current thread has not been interrupted.
              </li>
              <li>
                <strong>unlock()</strong>: Unlocks the Lock instance. Typically,
                a Lock implementation will only allow the thread that has locked
                the Lock to call this method.
              </li>
            </ul>
            <h3 id="ReentrantLock">
              <a
                href="#ReentrantLock"
                class="headerlink"
                title="ReentrantLock"
              ></a
              >ReentrantLock
            </h3>
            <ul>
              <li>
                <strong>ReentrantLock(boolean fair)</strong>: Creates an
                instance of ReentrantLock with the given fairness policy.
              </li>
              <li>
                <strong>getQueueLength()</strong>: Returns an estimate of the
                number of threads waiting to acquire this lock.
              </li>
              <li>
                <strong>isHeldByCurrentThread()</strong>: Queries if this lock
                is held by the current thread.
              </li>
              <li>
                <strong>isLocked()</strong>: Queries if this lock is held by the
                current thread.
              </li>
              <li>
                <strong>isFair()</strong>: Returns true if this lock has
                fairness set true.
              </li>
            </ul>
            <h3 id="ReadWriteLock">
              <a
                href="#ReadWriteLock"
                class="headerlink"
                title="ReadWriteLock"
              ></a
              >ReadWriteLock
            </h3>
            <p>
              Implementation of extended mutual exclusion of readers and
              writers. It allows multiple threads to read a certain resource,
              but only one to write it, at a time.
            </p>
            <ul>
              <li>
                <p>
                  <strong>Read Lock</strong>: If no threads have locked the
                  ReadWriteLock for writing, and no thread have requested a
                  write lock (but not yet obtained it). Thus, multiple threads
                  can lock the lock for reading.
                </p>
              </li>
              <li>
                <p>
                  <strong>Write Lock</strong>: If no threads are reading or
                  writing. Thus, only one thread at a time can lock the lock for
                  writing.
                </p>
                <p>
                  private ReadWriteLock readWriteLock &#x3D; new
                  ReentrantReadWriteLock();<br />
                  private void reader() {<br />
                  readWriteLock.readLock().lock();<br /><br />
                  &#x2F;&#x2F; multiple readers can enter this section<br />
                  &#x2F;&#x2F; if not locked for writing, and not writers
                  waiting<br />
                  &#x2F;&#x2F; to lock for writing.<br /><br />
                  readWriteLock.readLock().unlock();<br />
                  }<br />
                  private void writer() {<br />
                  readWriteLock.writeLock().lock();<br /><br />
                  &#x2F;&#x2F; only one writer can enter this section,<br />
                  &#x2F;&#x2F; and only if no threads are currently reading.<br /><br />
                  readWriteLock.writeLock().unlock();<br />
                  }
                </p>
              </li>
            </ul>
            <h3 id="StampedLock">
              <a href="#StampedLock" class="headerlink" title="StampedLock"></a
              >StampedLock
            </h3>
            <h2 id="Monitor">
              <a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor
            </h2>
            <ul>
              <li>Provides mutual exclusion</li>
              <li>
                Provides conditional synchronization allowing one process to be
                locked and another process to unlock it.
              </li>
              <li>
                Provide a mechanism for threads to temporarily give up for a
                exclusive access in order to wait for some condition to be met,
                before regaining exclusive access and resuming their task.
              </li>
            </ul>
            <p>
              A monitor consists of a <strong>lock</strong> and
              <strong>condition variables</strong>. In Java every object can act
              as a <strong>monitor</strong>, the mutual exclusion is define by
              mutual exclusion by <strong>synchronized</strong> on the object
              and the condition variables are provided with following method in
              the synchronized object.
            </p>
            <ul>
              <li>
                <strong>wait()</strong>: Causes the current thread to wait until
                another thread invokes the <strong>notify()</strong> method or
                the <strong>notifyAll()</strong> method for this object
              </li>
              <li>
                <strong>notify()</strong>: Wakes up a single thread that is
                waiting on this object’s monitor.
              </li>
              <li>
                <strong>notifyAll()</strong>: Wakes up all threads that are
                waiting on this object’s monitor.
              </li>
            </ul>
            <p>
              Those methods can only be invoked within a synchronized statement
              or synchronized method. When a thread is locked in the condition
              variables the mutual exclusion is released automatically.
            </p>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/b55abe7deed23e639ca6b55e671b3728b43f307f/core/src/main/java/core/concurrent/MonitorBarrier.java"
                >MonitorBarrier</a
              >
            </p>
            <p>
              It is not possible to notify a particular thread. Because
              unexpected activations can occur, we have to implement a
              protection mechanism in <strong>wait()</strong>. It is recommended
              to block the threads with a guard condition when notify all
              threads and all will be blocked again except the one that meets
              the condition.
            </p>
            <p>
              With locks we can have several conditions rather the single one,
              we can create a condition with
              <strong>newCondition()</strong> that return a object with
              following methods.
            </p>
            <ul>
              <li><strong>await()</strong></li>
              <li><strong>signal()</strong></li>
              <li><strong>signalAll()</strong></li>
            </ul>
            <p>
              It is necesarry to have <strong>await</strong> inside a loop due
              to the expected activation.
            </p>
            <p>
              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/vitaminac/code/blob/62a4cd718375cfb4725a671a7212a2583be2df5c/core/src/main/java/core/concurrent/LockBarrier.java"
                >LockBarrier</a
              >
            </p>
            <h2 id="Exchanger">
              <a href="#Exchanger" class="headerlink" title="Exchanger"></a
              >Exchanger
            </h2>
            <p>
              Exchanger allows two threads to exchange objects with each other
            </p>
            <pre><code>public V exchange (V e) throws InterruptedException
</code></pre>
            <ul>
              <li>
                The first thread that executes exchange() is blocked until the
                other thread also executes that method.
              </li>
              <li>
                When the second thread executes exchange() both threads exchange
                the values passed as a parameter and continue their execution.
              </li>
            </ul>
            <hr />
            <pre><code>private Exchanger&lt;Integer&gt; exchanger = new Exchanger&lt;Integer&gt;();
</code></pre>
            <hr />
            <pre><code>public static void producer() throws InterruptedException &#123;
    for(int i = 0; i &lt; N; i++) &#123;
        exchanger.exchange(i);
    &#125;
&#125;
</code></pre>
            <hr />
            <pre><code>public static void consumer() throws InterruptedException &#123;
    for(int i = 0; i &lt; N; i++) &#123;
        exchanger.exchange(i);
    &#125;
&#125;
</code></pre>
            <h2 id="CountDownLatch">
              <a
                href="#CountDownLatch"
                class="headerlink"
                title="CountDownLatch"
              ></a
              >CountDownLatch
            </h2>
            <p>
              One or more threads invoke <strong>await()</strong> and that
              blocks them waiting for <strong>countDown()</strong> is invoked as
              many times as specified in the object’s constructor.
            </p>
            <h2 id="CyclicBarrier">
              <a
                href="#CyclicBarrier"
                class="headerlink"
                title="CyclicBarrier"
              ></a
              >CyclicBarrier
            </h2>
            <p>
              <strong>CyclicBarrier(int parties, Runnable barrierAction)</strong
              >: Number of barrier threads and code executed when the barrier is
              tripped.
            </p>
            <p>
              <strong>await()</strong>: blocks the thread until the other
              threads arrive.
            </p>
            <h2 id="Concurrent-Collections">
              <a
                href="#Concurrent-Collections"
                class="headerlink"
                title="Concurrent Collections"
              ></a
              >Concurrent Collections
            </h2>
            <p>All actions performed on the collection must be synchronized.</p>
            <pre><code>public String deleteLast(List&lt;String&gt; list) &#123;
    synchronized (list) &#123;
        int lastIndex = list.size() - 1;
        return list.remove(lastIndex);
    &#125;
&#125;
</code></pre>
            <h3 id="Synchronization-Wrappers">
              <a
                href="#Synchronization-Wrappers"
                class="headerlink"
                title="Synchronization Wrappers"
              ></a
              >Synchronization Wrappers
            </h3>
            <ul>
              <li>Collections.synchronizedList</li>
              <li>Collections.synchronizedMap</li>
              <li>Collections.synchronizedSet</li>
            </ul>
            <h3 id="BlockingQueue">
              <a
                href="#BlockingQueue"
                class="headerlink"
                title="BlockingQueue"
              ></a
              >BlockingQueue
            </h3>
            <p>
              It is a <strong>thread-safe</strong> queue which is thread safe to
              put elements into, and take elements out of from. If the queue is
              full, the <strong>put(E)</strong> methods are locked until there
              is space. If the queue is empty then <strong>take()</strong> will
              block the thread until one element is available.
            </p>
            <p><img src="blocking-queue.png" alt="BlockingQueue" /></p>
            <ul>
              <li>
                <strong>put(e)</strong>: Blocks until operation can be performed
              </li>
              <li>
                <strong>offer(e, time, unit)</strong>: Blocks and returns false
                if the operation is not performed in the indicated time
              </li>
              <li>
                <strong>take()</strong>: Blocks until operation can be performed
              </li>
              <li>
                <strong>poll(time, unit)</strong>: Bloquea y devuelve null si no
                se realiza la operación en el tiempo indicado.
              </li>
            </ul>
            <p>Implementations:</p>
            <ul>
              <li>ArrayBlockingQueue</li>
              <li>LinkedBlockingQueue</li>
              <li>PriorityBlockingQueue</li>
              <li>
                SynchronousQueue
                <ul>
                  <li>just allow a single element</li>
                </ul>
              </li>
              <li>
                DelayQueue
                <ul>
                  <li>keeps items in the queue for a specified time</li>
                </ul>
              </li>
              <li>LinkedBlockingDeque</li>
              <li>
                TransferQueue
                <ul>
                  <li>
                    <p>
                      calling <strong>transfer(E e)</strong> will guarantee that
                      all existing queue items will be processed before the
                      transferred item<br />an element
                    </p>
                  </li>
                  <li>
                    <p>LinkedTransferQueue</p>
                    <p>public class Producer implements Runnable {</p>
                    <pre><code>protected BlockingQueue queue = null;

public Producer(BlockingQueue queue) &#123;
    this.queue = queue;
&#125;

public void run() &#123;
    try &#123;
        queue.put(&quot;1&quot;);
        Thread.sleep(1000);
        queue.put(&quot;2&quot;);
        Thread.sleep(1000);
        queue.put(&quot;3&quot;);
    &#125; catch (InterruptedException e) &#123;
        e.printStackTrace();
    &#125;
&#125;
</code></pre>
                    <p>}</p>
                    <p>public class Consumer implements Runnable {</p>
                    <pre><code>protected BlockingQueue queue = null;

public Consumer(BlockingQueue queue) &#123;
    this.queue = queue;
&#125;

public void run() &#123;
    try &#123;
        System.out.println(queue.take());
        System.out.println(queue.take());
        System.out.println(queue.take());
    &#125; catch (InterruptedException e) &#123;
        e.printStackTrace();
    &#125;
&#125;
</code></pre>
                    <p>}</p>
                  </li>
                </ul>
              </li>
            </ul>
            <h3 id="ConcurrentMap">
              <a
                href="#ConcurrentMap"
                class="headerlink"
                title="ConcurrentMap"
              ></a
              >ConcurrentMap
            </h3>
            <p>
              It represents a extended Map’s interface which is capable of
              handing concurrent access to it.
            </p>
            <ul>
              <li>
                <strong>compute(K key, remappingFunction)</strong>: map for the
                specified key and its current mapped value (or null if there is
                no current mapping
              </li>
              <li>
                <strong>putIfAbsent(K key, V value)</strong>: If the specified
                key is not already associated with a value, associate it with
                the given value.
              </li>
              <li>
                <strong>replace(K key, V value)</strong>: Replaces the entry for
                a key only if currently mapped to some value.
              </li>
              <li>
                <strong>replace(K key, V oldValue, V newValue)</strong>:
                Replaces the entry for a key only if currently mapped to a given
                value.
              </li>
            </ul>
            <p>Implementations:</p>
            <ul>
              <li><strong>ConcurrentHashMap</strong></li>
              <li><strong>ConcurrentSkipListMap</strong></li>
            </ul>
            <h3 id="CopyOnWrite">
              <a href="#CopyOnWrite" class="headerlink" title="CopyOnWrite"></a
              >CopyOnWrite
            </h3>
            <p>
              Copy-on write collections allow secure concurrent access because
              they are unchanging objects. When they are modified, a copy is
              created for subsequent readings. As it is expensive to make the
              copy when it is modified, this structure is designed for cases
              where reads are much more common than writes
            </p>
            <h4 id="CopyOnWriteArrayList">
              <a
                href="#CopyOnWriteArrayList"
                class="headerlink"
                title="CopyOnWriteArrayList"
              ></a
              >CopyOnWriteArrayList
            </h4>
            <h4 id="CopyOnWriteArraySet">
              <a
                href="#CopyOnWriteArraySet"
                class="headerlink"
                title="CopyOnWriteArraySet"
              ></a
              >CopyOnWriteArraySet
            </h4>
            <h3 id="ConcurrentSkipListSet">
              <a
                href="#ConcurrentSkipListSet"
                class="headerlink"
                title="ConcurrentSkipListSet"
              ></a
              >ConcurrentSkipListSet
            </h3>
            <h3 id="ConcurrentLinkedQueue">
              <a
                href="#ConcurrentLinkedQueue"
                class="headerlink"
                title="ConcurrentLinkedQueue"
              ></a
              >ConcurrentLinkedQueue
            </h3>
            <h3 id="ConcurrentLinkedDeque">
              <a
                href="#ConcurrentLinkedDeque"
                class="headerlink"
                title="ConcurrentLinkedDeque"
              ></a
              >ConcurrentLinkedDeque
            </h3>
            <h2 id="Thread-Pool">
              <a href="#Thread-Pool" class="headerlink" title="Thread Pool"></a
              >Thread Pool
            </h2>
            <p>
              A thread pool is responsible for managing the execution of a group
              of threads. They contain a queue that is responsible for managing
              and waiting for tasks to run. Threads are running continuously,
              checking for a new task in the queue to perform.
            </p>
            <p><img src="ThreadPool.png" alt="Thread Pool" /></p>
            <h3 id="Executor">
              <a href="#Executor" class="headerlink" title="Executor"></a
              >Executor
            </h3>
            <p>Interface that allows launching new tasks.</p>
            <h3 id="ExecutorService">
              <a
                href="#ExecutorService"
                class="headerlink"
                title="ExecutorService"
              ></a
              >ExecutorService
            </h3>
            <p>
              Implements the Executor interface, adding the functionality of
              thread life cycle management
            </p>
            <ul>
              <li>
                <p>
                  <strong>newSingleThreadExecutor()</strong>: Create a single
                  thread.
                </p>
              </li>
              <li>
                <p>
                  <strong>newFixedThreadPool</strong>: Create a thread pool that
                  contains the number of threads we need.
                </p>
              </li>
              <li>
                <p><strong>newCachedThreadPool()</strong></p>
                <ul>
                  <li>
                    Create a thread pool that will launch new threads when
                    necessary, but will try to reuse old ones when they become
                    available.
                  </li>
                  <li>
                    They are recommended for applications that perform very
                    short tasks
                  </li>
                  <li>
                    Threads that have not been used for more than 60 seconds end
                    and are removed from the pool.
                  </li>
                </ul>
              </li>
              <li>
                <p>
                  Each task is executed using the
                  <strong>execute()</strong> method of the ExecutorService that
                  we have created.
                </p>
              </li>
              <li>
                <p>
                  It is necessary to finish each ExecutorService that we use
                  with<strong>shutdown()</strong>.
                </p>
                <p>
                  ExecutorService executor &#x3D;
                  Executors.newSingleThreadExecutor();<br />
                  for (int i &#x3D; 0; i &lt; 10; i++) {<br />
                  executor.execute(() -&gt; Thread.sleep(100));<br />
                  }<br />
                  executor.shutdown();
                </p>
              </li>
            </ul>
            <p>
              If we need a task to return a result, we have to use
              <strong>Callable</strong> interface. We use
              <strong>submit()</strong>, which execute the task and it a
              Future&lt;T&gt;.
            </p>
            <pre><code>public class RunnableExample implements Runnable &#123;
    @Override
    public void run() &#123;
        // Task code
    &#125;
&#125;
public class CallableExample implements Callable&lt;T&gt; &#123;
    @Override
    public T call() throws Exception &#123;
        // Task code
        return null;
    &#125;
&#125;
</code></pre>
            <h4 id="Shutdown">
              <a href="#Shutdown" class="headerlink" title="Shutdown"></a
              >Shutdown
            </h4>
            <p>
              The ExecutorService needs to be shut down when you are finished
              using it. If not, it will keep the JVM running, even when all
              other threads have been shut down.
            </p>
            <h3 id="ScheduledExecutorService">
              <a
                href="#ScheduledExecutorService"
                class="headerlink"
                title="ScheduledExecutorService"
              ></a
              >ScheduledExecutorService
            </h3>
            <p>
              The java.util.concurrent.ScheduledExecutorService is an
              ExecutorService which can schedule tasks to run after a delay, or
              to execute repeatedly with a fixed interval of time in between
              each execution.
            </p>
            <pre><code>ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(4);
</code></pre>
            <h4 id="schedule-Callable-task-long-delay-TimeUnit-timeunit">
              <a
                href="#schedule-Callable-task-long-delay-TimeUnit-timeunit"
                class="headerlink"
                title="schedule(Callable task, long delay, TimeUnit timeunit)"
              ></a
              >schedule(Callable task, long delay, TimeUnit timeunit)
            </h4>
            <p>
              This method schedules the given Callable for execution after the
              given delay.
            </p>
            <p>
              The method returns a ScheduledFuture which you can use to either
              cancel the task before it has started executing, or obtain the
              result once it is executed.
            </p>
            <h4 id="schedule-Runnable-task-long-delay-TimeUnit-timeunit">
              <a
                href="#schedule-Runnable-task-long-delay-TimeUnit-timeunit"
                class="headerlink"
                title="schedule(Runnable task, long delay, TimeUnit timeunit)"
              ></a
              >schedule(Runnable task, long delay, TimeUnit timeunit)
            </h4>
            <p>
              This method works like the method version taking a Callable as
              parameter, except a Runnable cannot return a value, so the
              ScheduledFuture.get() method returns null when the task is
              finished.
            </p>
            <h4
              id="scheduleAtFixedRate-Runnable-task-long-initialDelay-long-period-TimeUnit-timeunit"
            >
              <a
                href="#scheduleAtFixedRate-Runnable-task-long-initialDelay-long-period-TimeUnit-timeunit"
                class="headerlink"
                title="scheduleAtFixedRate(Runnable task, long initialDelay, long period, TimeUnit timeunit)"
              ></a
              >scheduleAtFixedRate(Runnable task, long initialDelay, long
              period, TimeUnit timeunit)
            </h4>
            <p>
              This method schedules a task to be executed
              <strong>periodically</strong>. The task is executed the first time
              after the <strong>initialDelay</strong>, and then recurringly
              every time the period expires.
            </p>
            <p>
              If any execution of the given task throws an exception, the task
              is no longer executed. If no exceptions are thrown, the task will
              continue to be executed until the
              <strong>ScheduledExecutorService is shut down</strong>.
            </p>
            <p>
              If a task takes longer to execute than the period between its
              scheduled executions, the next execution will start after the
              current execution finishes. The scheduled task will not be
              executed by more than one thread at a time.
            </p>
            <h4
              id="scheduleWithFixedDelay-Runnable-task-long-initialDelay-long-period-TimeUnit-timeunit"
            >
              <a
                href="#scheduleWithFixedDelay-Runnable-task-long-initialDelay-long-period-TimeUnit-timeunit"
                class="headerlink"
                title="scheduleWithFixedDelay(Runnable task, long initialDelay, long period, TimeUnit timeunit)"
              ></a
              >scheduleWithFixedDelay(Runnable task, long initialDelay, long
              period, TimeUnit timeunit)
            </h4>
            <p>
              This method works very much like scheduleAtFixedRate() except that
              the period is interpreted differently.
            </p>
            <p>
              In the scheduleAtFixedRate() method the period is interpreted as a
              delay between the start of the previous execution, until the start
              of the next execution.
            </p>
            <p>
              In this method, however, the period is interpreted as the delay
              between the end of the previous execution, until the start of the
              next. The delay is thus between finished executions, not between
              the beginning of executions.
            </p>
            <h2 id="Reference">
              <a href="#Reference" class="headerlink" title="Reference"></a
              >Reference
            </h2>
            <p><img src="java-concurrent.png" alt="Java Concurrent" /></p>
            <ul>
              <li>
                <a
                  target="_blank"
                  rel="noopener"
                  href="http://tutorials.jenkov.com/java-concurrency/index.html"
                  >Java Concurrency and Multithreading Tutorial</a
                >
              </li>
              <li>
                <a
                  target="_blank"
                  rel="noopener"
                  href="http://tutorials.jenkov.com/java-util-concurrent"
                  >Java Concurrency Utilities</a
                >
              </li>
              <li>
                <a
                  target="_blank"
                  rel="noopener"
                  href="https://www.baeldung.com/java-util-concurrent"
                  >Overview of the java.util.concurrent</a
                >
              </li>
              <li>
                <a
                  target="_blank"
                  rel="noopener"
                  href="https://www.coursera.org/learn/parallel-programming-in-java"
                  >Parallel Programming in Java</a
                >
              </li>
            </ul>

            <hr />

            <ul class="list-group">
              <li
                class="list-group-item list-group-item-action flex-column align-items-start"
              >
                <a target="_parent" href="/posts/Java-Stream/"> Java Stream </a>
              </li>
            </ul>

            <ul class="pagination pager">
              <li class="page-item">
                <a
                  target="_parent"
                  class="page-link"
                  href="/posts/Prestamo/"
                  data-toggle="tooltip"
                  data-placement="top"
                  title="Como calcular un préstamo"
                  >&larr; Previous Post</a
                >
              </li>

              <li class="page-item ms-auto">
                <a
                  target="_parent"
                  class="page-link"
                  href="/posts/Client-Centric-Consistency-Models/"
                  data-toggle="tooltip"
                  data-placement="top"
                  title="Client-Centric Consistency Models"
                  >Next Post &rarr;</a
                >
              </li>
            </ul>
          </div>
        </div>

        <div class="row justify-content-center">
          <!-- Sidebar Container -->

          <div class="col-lg-8` col-md-10 sidebar-container">
            <!-- Friends Blog -->
          </div>
        </div>
      </div>
    </article>
    <!-- Custom Theme JavaScript -->
    <script type="text/javascript" src="/js/blog.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
    <script>
      $(document).ready(function () {
        anchors.add("p");
      });
    </script>

    <!-- mathjax -->
    <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          jax: ["input/TeX", "output/SVG"],
          extensions: ["tex2jax.js"],
          showMathMenu: false,
          SVG: { useGlobalCache: false },
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
              processEscapes: true
          },
          TeX: {
              equationNumbers: { autoNumber: "AMS" },
              noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
              Macros: { href: "{}" }
          }
      });
    </script>
    <script
      type="text/javascript"
      async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML-full"
    ></script>

    <!-- jquery.tagcloud.js -->
    <script>
      // only load tagcloud.js in tag.html
      if ($("#tag_cloud").length !== 0) {
        async("https://vitaminac.github.io/js/jquery.tagcloud.js", function () {
          $.fn.tagcloud.defaults = {
            //size: {start: 1, end: 1, unit: 'em'},
            color: {
              start: "#bbbbee",
              end: "#0085a1",
            },
          };
          $("#tag_cloud a").tagcloud();
        });
      }
    </script>

    <script type="text/javascript" src="/js/common.js"></script>

    <script type="text/javascript">
      $("code").addClass("language-java");
    </script>
    <script type="text/javascript" src="/js/prism.js"></script>
    <script type="text/javascript">
      addCSS("//css/prism.css");
      Prism.highlightAll();
    </script>

    <!-- render ipynb file -->

    <!-- render ipynb file -->

    <script type="text/javascript" src="/js/render.js"></script>
    <script type="text/javascript">
      $(document).ready(function () {
        render_files("java", "java");
      });
    </script>
  </body>
</html>
